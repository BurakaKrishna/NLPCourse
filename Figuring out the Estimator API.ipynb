{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "This notebook is my live notes for figuring out how to use Tensorflows  Estimator API. \n",
    "I read the [official docs](https://www.tensorflow.org/guide/estimators) but they were a bit vauge for my taste, e.g. I couldn't read them and know what to do. \n",
    "\n",
    "For context, I have a toy problem, that has numbers as words in German and the actual words. I want to do two toy problems, one is classify whether a given word is even or odd. The other is convert from word to number using [NALU](https://arxiv.org/abs/1808.00508). It's 20:30 now and I have a baby that's switching between crying, feeding and sleeping. Let's see how far he lets us get. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step one - \"Literature Review\"\n",
    "The official docs point to a collection of [official models](https://github.com/tensorflow/models/tree/master/official) that are well maintained and serve as references for the high level APIs like Estimator. This is great. Even better, they have an implementation of the [Transformer model](https://github.com/tensorflow/models/tree/master/official/transformer) which is in the realm of NLP. That;s articulrly important because dataloading in NLP is a black art and getting it to play nice with a new API will be blacker than black so it's nice to have a reference to copy paste from\n",
    "![funny](https://i.gr-assets.com/images/S/compressed.photo.goodreads.com/books/1457364208i/29437996._UY630_SR1200,630_.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Caveat - The Transformer implementation is too good for me\n",
    "The implementation in the transormer model is a bit too good. It covers a lot of things I don't really need now like Bleu scores, running on TPUs and distributed training. Yes, these are highlights of the Estimator API but they are highlights I don't need now. So really the first thing I'll do is mark what I need to keep and delete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we know\n",
    "\n",
    "So basically the Estimator API says \"Give me a function that returns Data, and another function that returns a model, and I'll combine them, run them, calculate the metrics, save checkpoints, distribute it across nodes and make you coffee. \n",
    "\n",
    "\n",
    "So what we need to figure out is \n",
    "* How to write a model function\n",
    "* What are the specifications for the data function\n",
    "    * Can we use feed dicts or only TFRecords ? \n",
    "    * It looks like we need to seperate examples and labels for the API, where should we do that ? \n",
    "    * Can we preproccess the text in Python. \n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to write a model function \n",
    "So the transformer model function is [here](https://github.com/tensorflow/models/blob/master/official/transformer/transformer_main.py#L69)\n",
    "Notably, it's signature is \n",
    "```python\n",
    "def model_fn(features, labels, mode, params):\n",
    "\n",
    "```\n",
    "I guess features is inputs, labels is labels, I know that mode is one of [Train,Test,Predict] or something semantically equaivalent. \n",
    "If you look [here]((https://github.com/tensorflow/models/blob/master/official/transformer/transformer_main.py#L81-L89) you'll see that the model returns something in the case that mode==PREDICT and then [here]((https://github.com/tensorflow/models/blob/master/official/transformer/transformer_main.py#L125-L138) something else if mode==TRAIN.\n",
    "\n",
    "Cool. so first thing we know is that it should do different things based on mode. This is actually super duper awesome because before this their wasn't a canonical way to make that seperation and every project reinvented the wheel. So while a bit complex, it's great. \n",
    "\n",
    "### What is the model_fn returning\n",
    "So when we look at what the model function is returing we see it returns an [EstimatorSpec](https://www.tensorflow.org/api_docs/python/tf/estimator/EstimatorSpec)  \n",
    "```python\n",
    "      return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "```\n",
    "Just looking at how it's called here this thing actually makes sense. \n",
    "The docs say\n",
    "\n",
    ">For mode == ModeKeys.TRAIN: required fields are loss and train_op.\n",
    "\n",
    ">For mode == ModeKeys.EVAL: required field is loss.\n",
    "\n",
    ">For mode == ModeKeys.PREDICT: required fields are predictions.\n",
    "\n",
    "\n",
    "So that tells us what the minumum we need to pass in. I wonder why we need to pass the loss into the estimator during training, since I assume it's implied in the training op that is minimizing the loss. But whatever.\n",
    "\n",
    "### Where did loss and train_op come from ?\n",
    "\n",
    "So we saw in that little python snippet that we pass loss and train_op but where did they come from ?\n",
    "So in the begining of the model_fn they do \n",
    "```python\n",
    "    model = transformer.Transformer(params, mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    logits = model(inputs, targets)\n",
    "```\n",
    "Where transformer is an import from some other directory. \n",
    "Then, once they've checked they are not in prediction mode, they calculate the loss\n",
    "```python\n",
    "    xentropy, weights = metrics.padded_cross_entropy_loss(\n",
    "        logits, targets, params[\"label_smoothing\"], params[\"vocab_size\"])\n",
    "    loss = tf.reduce_sum(xentropy) / tf.reduce_sum(weights)\n",
    "```\n",
    "Then they check if they are in eval or train mode, and if they are in train mode they also set up the train op \n",
    "```python\n",
    "      train_op, metric_dict = get_train_op_and_metrics(loss, params)\n",
    "```\n",
    "Where get_train_op_and_metrics is defined in the file. \n",
    "\n",
    "### Two patterns emerge\n",
    "The first pattern to emerge is that they calculate only what is needed. Instead of saying calculate we can say they only set up the graph-ops that are needed. E.g. they don't make the train_op if they don't need it. I wonder if this is just good engineering or serves a more \"practical purpose\", e.g. to leave space on GPU or someething. \n",
    "\n",
    "Second pattern to emerge, which is **more important** is their use of imports and helper functions. Obviously this is a good pratice, and I mention it because i feel that when I copy and paste from X I'm not always confident about what \"style\" of programming I can use. This holds especially true in ML and frontend code where the software engineering chops vary wildly within the respective communities. But I digress\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Who calls the model_fn ?\n",
    "So we've seen that the model_fn they define returns an esitmator spec when it gets data and a mode. Who calls it the model_fn and where does it get the data from ? \n",
    "Well [here]((https://github.com/tensorflow/models/blob/master/official/transformer/transformer_main.py#L499-L502) is an example. Let's copy paste it!\n",
    "\n",
    "```python\n",
    "    return tf.estimator.Estimator(\n",
    "        model_fn=model_fn, model_dir=flags_obj.model_dir, params=params,\n",
    "        config=tf.estimator.RunConfig(train_distribute=distribution_strategy))\n",
    "```\n",
    "\n",
    "Cool. So it makes sense that the Estimator class will call the model function, which will in turn return an estimator spec based on the mode. The thing is, model_fn is called with features and labels, where did they come from ? It's not obvious just from looking at this function. I can only assume that it's somehow specified in params. I vaugely remembered something about an input_fn so I searched the code for it and found \n",
    "[this morsel]((https://github.com/tensorflow/models/blob/master/official/transformer/transformer_main.py#L334-L337) \n",
    "```python\n",
    "    estimator.train(\n",
    "        dataset.train_input_fn,\n",
    "        steps=schedule_manager.single_iteration_train_steps,\n",
    "        hooks=train_hooks)\n",
    "```\n",
    "And so, I realize that the estimator instance returned from instantiaing the Estimator class with our model_fn has a method on it called train that accepts an input function. Shoutout to timeless [Execution in the Kingdom of nouns](https://steve-yegge.blogspot.com/2006/03/execution-in-kingdom-of-nouns.html).\n",
    "It's actually very sensible, an instance of an estimator has a bunch of methods, like train, evaluate and predict, which happen to correspond to the things we'd like to do with a model. In any of these cases, we need to provide data to our model, which is done through an input_fn. We can do a bunch of extra fancy things which we'll get to later. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A question is answered! We now know the constraints on the data input\n",
    "We can now go look at the docs for the estimators [train](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#train) method and see what we can pass around in the input_fn. To quote the docs\n",
    "\n",
    "        input_fn: A function that provides input data for training as minibatches. See Premade Estimators for more information. The function should construct and return one of the following: \n",
    "        * A tf.data.Dataset object: Outputs of Dataset object must be a tuple (features, labels) with same constraints as below. \n",
    "        * A tuple (features, labels): Where features is a tf.Tensor or a dictionary of string feature name to Tensor and labels is a Tensor or a dictionary of string label name to Tensor. \n",
    "        Both features and labels are consumed by model_fn. They should satisfy the expectation of model_fn from inputs.\n",
    "\n",
    "When we set out on this adventure I asked \n",
    "* Can we use feed dicts or only TFRecords ? \n",
    "* It looks like we need to seperate examples and labels for the API, where should we do that ? \n",
    "* Can we preproccess the text in Python. \n",
    "\n",
    "Let's answer them\n",
    "\n",
    "### Can we use feed dicts or only TFRecords ? \n",
    "Apperently no way to use feeddicts. But, we don't need to use TFRecords, we just need a function that reads data on the fly and returns tensors.\n",
    "### It looks like we need to seperate examples and labels for the API, where should we do that ? \n",
    "Well, input function says to return a Dataset object that returns a tuple. It isn't very specific about what that tuple should be. \n",
    "\n",
    "I'm not being nitpicky, I like to pass a lot of tensors in dictionaries, for example, I want to pass my examples in a tensor and another tensor with their lengths and put both of those in a dict. Apperently, I can, so long as I return a tuple of two dicts.\n",
    "\n",
    "I'll guestimate that the tensorflow folks were trying to avoid stuff like this when desiging the API. Probably the logic is that if you follow it to the letter you'll have super portable models that you can share and swap out parts. In my way, with the dicts, your model_fn now needs to parse dicts. Works for me. \n",
    "\n",
    "### Can we preproccess the text in Python ?\n",
    "I think we can. We'll try to do that in a bit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up for Tensorboard\n",
    "Let's face it, the best part of doing deep learning is watching the loss go down on Tensorboard. While the estimator API promises to let us do that for free, we haven't seen how. \n",
    "\n",
    "So actually, in the Transformer example they have this cool function that gets a loss and some params and returns both the train ops and the metrics we want in tensorflow. It's [here](https://github.com/tensorflow/models/blob/master/official/transformer/transformer_main.py#L166-L194). Basically they have a dict called metric_dict and it has names of scalars and scalrs. Then they run a function, [record_scalars](https://github.com/tensorflow/models/blob/master/official/transformer/transformer_main.py#L141) and that sets up the scalars for tensorboard. \n",
    "\n",
    "If you dig around, they do the same thing in slightly different ways, but really their is no magic here. You call tf.summary.X (or tf.contrib.summary.X)  and Estimator will take care of the rest. Amen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Summary - Setting up some context\n",
    "As I mentioned, I have a toy task! It consists of taking a word in German that represents a number and predicting if it is even or odd. Conveniently, I have a program that gives me dicts whose keys are numbers and values are  their German word equivalent. Check it out (Disclaimer, I wrote this program and my German is shameful so maybe its wrong) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{8: 'acht',\n",
       " 14: 'vierzehn',\n",
       " 16: 'sechszehn',\n",
       " 19: 'neunzehn',\n",
       " 40: 'undvierzig',\n",
       " 50: 'undfünfzig',\n",
       " 65: 'fünfundsechzig',\n",
       " 71: 'einundsiebzig',\n",
       " 73: 'dreiundsiebzig'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.numtoWord import createNum2WordDict\n",
    "createNum2WordDict(size=10,high=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! \n",
    "Now, let's see how we make that into something that maps Words to even numbers. (0 means odd, 1 means even)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: ('eins', 0),\n",
       " 5: ('fünf', 0),\n",
       " 21: ('einundzwanzig', 0),\n",
       " 41: ('einundvierzig', 0),\n",
       " 47: ('siebenundvierzig', 0),\n",
       " 56: ('sechsundfünfzig', 1),\n",
       " 66: ('sechsundsechzig', 1),\n",
       " 77: ('siebenundsiebzig', 0),\n",
       " 80: ('undachtzig', 1),\n",
       " 95: ('fünfundneunzig', 0)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = createNum2WordDict(size=10,high=100)\n",
    "d = {key: (val,(key+1)%2) for key,val in d.items()}\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, so now that I have my data here is what I want\n",
    "1. A model that \n",
    "    * Is an LSTM\n",
    "    * Reads the words charechter by charechter\n",
    "    * Predicts if they are even or odd\n",
    "2. An input function that \n",
    "    * calls my fancy function above and returns tensors in the proper format\n",
    "3. An Estimarot that\n",
    "    * Uses my model via a model_fn and my input_fn to train and evaluate \n",
    "    * To see progress and accuracy in Tensorboard\n",
    "    * As a bonus, to do a one line deploy of this to Google-ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "So now I can summarize what I've learnt in light of what I want to do, e.g. derive a recipe. \n",
    "Basically\n",
    "1. Find your data\n",
    "2. Write a function that returns a Dataset object which in itself returns a tuple\n",
    "3. Define your model somewhere, as a function that returns logits / predictions\n",
    "4. Write a model_fn, \n",
    "    * Takes as input\n",
    "        * features and labels are the tuple from your input function\n",
    "        * mode is one of the values of [ModeKeys](https://www.tensorflow.org/api_docs/python/tf/estimator/ModeKeys)\n",
    "        * params are paramaters we haven't disucssed \n",
    "    * Returns an instance of an EstimatorSpec\n",
    "        * That does what needs to be done based on the mode (e.g. trains, or just predicts) \n",
    "5. Instantiate an Estimator with the model_fn\n",
    "6. Call estimator.train/eval/predict with the relevant input_fn\n",
    "\n",
    "It is now 22:07, so it took me an hour and forty to figure this out. My child did not interfere much so this was more or less continuous. \n",
    "\n",
    "Armed with this new knoweledge, I'm going to walk the dogs and then actually do this\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model(inputs,labels,params):\n",
    "    '''\n",
    "        Inputs a dict of tensors {\"sequences\":[?,?],\"lengths\":[?]}\n",
    "        labels a tesnor of shape [?] batch size\n",
    "        returns logits [?] batch_size\n",
    "    '''\n",
    "    lengths = inputs[\"lengths\"]\n",
    "    sequences = inputs[\"sequences\"]\n",
    "    char_embeddings = tf.get_variable(\"char_embeddings\",[params['vocab_size'], params['hidden_size']],dtype=tf.float64)\n",
    "    embedded = tf.nn.embedding_lookup(char_embeddings, sequences)\n",
    "    \n",
    "    cell = tf.nn.rnn_cell.LSTMCell(num_units=params['hidden_size'],dtype=tf.float64)\n",
    "    outputs, states = tf.nn.bidirectional_dynamic_rnn(cell,cell, embedded,sequence_length=lengths,\n",
    "                                   dtype=tf.float64)\n",
    "    state = tf.concat([states[0][0],states[1][0]],axis=1)\n",
    "    logits = tf.layers.dense(state,units=params['hidden_size'],activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(state,units=1,activation=None)\n",
    "    return tf.squeeze(logits)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.numtoWord import createNum2WordDict, vocab\n",
    "def generator_function(params):\n",
    "    while True:\n",
    "        d = createNum2WordDict(size=100,high=params['max_num'])\n",
    "        for value,word in d.items():\n",
    "            if value==0:\n",
    "                continue\n",
    "            ids = [vocab[char] for char in word]\n",
    "            length = len(word)\n",
    "            yield (ids,length,value %2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(params):\n",
    "    generator = lambda : generator_function(params)\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        generator=generator,\n",
    "        output_types=(tf.int64,tf.int64,tf.double),\n",
    "        output_shapes=(tf.TensorShape([None]),tf.TensorShape([]),tf.TensorShape([]))\n",
    "    )\n",
    "    dataset =dataset.padded_batch(\n",
    "    params['batch_size'],\n",
    "    padded_shapes=(tf.TensorShape([None]),tf.TensorShape([]),tf.TensorShape([]))\n",
    "    )\n",
    "    \n",
    "    dataset = dataset.map(lambda x,y,z: ({\"sequences\":x,\"lengths\":y},z))\n",
    "    return dataset\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIde hack, try the model out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess = tf.InteractiveSession()\n",
    "# with tf.variable_scope(\"new18\"):\n",
    "#     ds =input_fn(params)\n",
    "#     it = ds.make_one_shot_iterator()\n",
    "#     next_el = it.get_next()\n",
    "#     sess.run([tf.global_variables_initializer()])\n",
    "#     logits = model(*next_el,params=params)\n",
    "#     opt = tf.train.AdamOptimizer(0.001)\n",
    "#     loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,labels=next_el[1])\n",
    "#     loss = tf.reduce_mean(loss)\n",
    "#     train = opt.minimize(loss)\n",
    "#     sess.run(tf.initialize_all_variables())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(100):\n",
    "#     _,l = sess.run([train,loss])\n",
    "#     if i%50 ==0:\n",
    "#         print(l)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back to making an estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp9q6asxpl\n",
      "INFO:tensorflow:Using config: {'_task_type': 'worker', '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_is_chief': True, '_task_id': 0, '_model_dir': '/tmp/tmp9q6asxpl', '_num_ps_replicas': 0, '_session_config': None, '_global_id_in_cluster': 0, '_save_checkpoints_steps': None, '_num_worker_replicas': 1, '_save_summary_steps': 100, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f367a68a3c8>, '_keep_checkpoint_max': 5, '_save_checkpoints_secs': 600, '_device_fn': None, '_tf_random_seed': None, '_master': '', '_train_distribute': None, '_log_step_count_steps': 100, '_service': None}\n"
     ]
    }
   ],
   "source": [
    "def model_fn(features,labels,mode,params):\n",
    "    with tf.variable_scope(\"model\"):\n",
    "        logits = model(features,labels,params)\n",
    "        loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,labels=labels)\n",
    "        loss = tf.reduce_mean(loss)\n",
    "        tf.summary.scalar(\"loss\",loss)\n",
    "        opt = tf.train.AdamOptimizer(0.001)\n",
    "        train = opt.minimize(loss,global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train)\n",
    "\n",
    "params = {\n",
    "    \"max_num\":500000000,\n",
    "    \"batch_size\":8,\n",
    "    \"hidden_size\":64,\n",
    "    \"vocab_size\":len(vocab)\n",
    "}\n",
    "\n",
    "\n",
    "        \n",
    "estimator = tf.estimator.Estimator(model_fn=model_fn,params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp9q6asxpl/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.7012469862025141, step = 1\n",
      "INFO:tensorflow:global_step/sec: 12.9669\n",
      "INFO:tensorflow:loss = 0.2502513232844756, step = 101 (7.713 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.4395\n",
      "INFO:tensorflow:loss = 0.6140142859200852, step = 201 (6.926 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.4142\n",
      "INFO:tensorflow:loss = 0.11638232972164511, step = 301 (7.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.3474\n",
      "INFO:tensorflow:loss = 0.0029722443195125555, step = 401 (7.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4479\n",
      "INFO:tensorflow:loss = 0.017131968475857507, step = 501 (8.734 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4908\n",
      "INFO:tensorflow:loss = 0.016594788126567, step = 601 (9.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.1765\n",
      "INFO:tensorflow:loss = 0.00029860709288709314, step = 701 (7.054 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.8463\n",
      "INFO:tensorflow:loss = 0.012677712857001729, step = 801 (6.736 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.80195\n",
      "INFO:tensorflow:loss = 0.02318602948412821, step = 901 (10.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8067\n",
      "INFO:tensorflow:loss = 0.00885067524698736, step = 1001 (9.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.4188\n",
      "INFO:tensorflow:loss = 0.00029688348265972334, step = 1101 (8.053 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.0521\n",
      "INFO:tensorflow:loss = 0.00017666182418764605, step = 1201 (7.661 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.54328\n",
      "INFO:tensorflow:loss = 0.00039004727120689475, step = 1301 (11.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.0151\n",
      "INFO:tensorflow:loss = 0.0006694897481130197, step = 1401 (7.677 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.7736\n",
      "INFO:tensorflow:loss = 0.0007846087309377539, step = 1501 (7.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.715\n",
      "INFO:tensorflow:loss = 0.0011971498109638527, step = 1601 (6.794 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.1754\n",
      "INFO:tensorflow:loss = 0.000687475927880653, step = 1701 (7.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.0717\n",
      "INFO:tensorflow:loss = 0.0006371602754532387, step = 1801 (8.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.8329\n",
      "INFO:tensorflow:loss = 8.687039662571557e-05, step = 1901 (8.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2755\n",
      "INFO:tensorflow:loss = 0.0003193342278261023, step = 2001 (8.872 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.60864\n",
      "INFO:tensorflow:loss = 0.00027099233413889305, step = 2101 (10.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.69\n",
      "INFO:tensorflow:loss = 0.0008750478247949624, step = 2201 (9.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.3005\n",
      "INFO:tensorflow:loss = 0.0016230364460289603, step = 2301 (9.706 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2061\n",
      "INFO:tensorflow:loss = 0.0007561905120491946, step = 2401 (8.924 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.1053\n",
      "INFO:tensorflow:loss = 5.636699410220749e-06, step = 2501 (9.005 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0788\n",
      "INFO:tensorflow:loss = 0.00019062180050518352, step = 2601 (9.026 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.4501\n",
      "INFO:tensorflow:loss = 6.823274475058852e-06, step = 2701 (6.920 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.0519\n",
      "INFO:tensorflow:loss = 0.00017447659319932813, step = 2801 (7.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.4476\n",
      "INFO:tensorflow:loss = 0.00028412497977219043, step = 2901 (7.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.1824\n",
      "INFO:tensorflow:loss = 2.9042715705172777e-05, step = 3001 (7.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.0962\n",
      "INFO:tensorflow:loss = 7.910615461600821e-06, step = 3101 (7.636 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.3017\n",
      "INFO:tensorflow:loss = 9.949588506944814e-06, step = 3201 (6.992 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.1795\n",
      "INFO:tensorflow:loss = 3.157040663705144e-05, step = 3301 (7.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.3675\n",
      "INFO:tensorflow:loss = 6.304211626303121e-05, step = 3401 (7.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.1277\n",
      "INFO:tensorflow:loss = 8.379587747215137e-05, step = 3501 (7.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.3687\n",
      "INFO:tensorflow:loss = 5.4407659987799495e-05, step = 3601 (6.960 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.2829\n",
      "INFO:tensorflow:loss = 0.00010081721157893049, step = 3701 (7.001 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.2249\n",
      "INFO:tensorflow:loss = 4.6739933277241676e-05, step = 3801 (7.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.4867\n",
      "INFO:tensorflow:loss = 8.857632719646987e-06, step = 3901 (7.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.0542\n",
      "INFO:tensorflow:loss = 3.0311361146630252e-06, step = 4001 (7.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.608\n",
      "INFO:tensorflow:loss = 9.305343381635896e-07, step = 4101 (7.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.6817\n",
      "INFO:tensorflow:loss = 2.3184106975938037e-05, step = 4201 (7.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.3008\n",
      "INFO:tensorflow:loss = 5.065058154341017e-05, step = 4301 (6.995 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.407\n",
      "INFO:tensorflow:loss = 9.410654185580323e-06, step = 4401 (6.938 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.9122\n",
      "INFO:tensorflow:loss = 1.4392492307396222e-05, step = 4501 (6.706 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.6942\n",
      "INFO:tensorflow:loss = 8.863944021206576e-05, step = 4601 (7.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.5955\n",
      "INFO:tensorflow:loss = 0.000138597597197614, step = 4701 (6.852 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.3634\n",
      "INFO:tensorflow:loss = 0.000297200716512336, step = 4801 (6.961 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.6651\n",
      "INFO:tensorflow:loss = 5.634351386791173e-06, step = 4901 (6.819 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.1392\n",
      "INFO:tensorflow:loss = 1.893931194792045e-05, step = 5001 (7.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.4455\n",
      "INFO:tensorflow:loss = 3.371188446736929e-05, step = 5101 (7.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.6916\n",
      "INFO:tensorflow:loss = 9.822003334929312e-07, step = 5201 (7.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.2507\n",
      "INFO:tensorflow:loss = 2.730771292252866e-06, step = 5301 (7.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.7835\n",
      "INFO:tensorflow:loss = 1.2315337013710893e-06, step = 5401 (7.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.3596\n",
      "INFO:tensorflow:loss = 1.2635720911046617e-05, step = 5501 (7.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.6132\n",
      "INFO:tensorflow:loss = 3.6890646556316763e-06, step = 5601 (7.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.663\n",
      "INFO:tensorflow:loss = 1.0213314550194213e-06, step = 5701 (7.897 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.9607\n",
      "INFO:tensorflow:loss = 7.458142960080017e-06, step = 5801 (6.684 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.4976\n",
      "INFO:tensorflow:loss = 5.623968127042874e-06, step = 5901 (6.898 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.413\n",
      "INFO:tensorflow:loss = 4.206122606939733e-07, step = 6001 (7.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.2229\n",
      "INFO:tensorflow:loss = 1.3756640627934315e-05, step = 6101 (7.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.8305\n",
      "INFO:tensorflow:loss = 2.7285344579748423e-05, step = 6201 (7.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.0209\n",
      "INFO:tensorflow:loss = 3.0173248136614595e-06, step = 6301 (7.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.2857\n",
      "INFO:tensorflow:loss = 1.4126564393852226e-05, step = 6401 (7.000 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.6232\n",
      "INFO:tensorflow:loss = 3.9450032746014745e-05, step = 6501 (7.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.6157\n",
      "INFO:tensorflow:loss = 8.371979074184417e-07, step = 6601 (6.842 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.5773\n",
      "INFO:tensorflow:loss = 1.6248119555694925e-05, step = 6701 (7.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.4669\n",
      "INFO:tensorflow:loss = 7.265742445201677e-06, step = 6801 (7.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.6062\n",
      "INFO:tensorflow:loss = 3.7389752020053747e-07, step = 6901 (7.933 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.3488\n",
      "INFO:tensorflow:loss = 4.225519302103631e-06, step = 7001 (6.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.5509\n",
      "INFO:tensorflow:loss = 4.180317898599879e-07, step = 7101 (7.380 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 14.5159\n",
      "INFO:tensorflow:loss = 2.2238573707311124e-07, step = 7201 (6.889 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.1284\n",
      "INFO:tensorflow:loss = 1.2628029895195088e-06, step = 7301 (6.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.0963\n",
      "INFO:tensorflow:loss = 1.1810582616483389e-05, step = 7401 (7.636 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.9665\n",
      "INFO:tensorflow:loss = 8.962258618314627e-07, step = 7501 (8.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.558\n",
      "INFO:tensorflow:loss = 7.040826027342545e-07, step = 7601 (7.959 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.7683\n",
      "INFO:tensorflow:loss = 1.3358522933482892e-06, step = 7701 (7.832 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.1234\n",
      "INFO:tensorflow:loss = 2.866227229156681e-07, step = 7801 (7.620 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7810 into /tmp/tmp9q6asxpl/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 12.906\n",
      "INFO:tensorflow:loss = 3.425541569615067e-06, step = 7901 (7.748 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.1475\n",
      "INFO:tensorflow:loss = 9.994866968136463e-05, step = 8001 (7.606 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.0581\n",
      "INFO:tensorflow:loss = 3.800020920586715e-07, step = 8101 (6.641 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.3806\n",
      "INFO:tensorflow:loss = 1.4602182865421342e-06, step = 8201 (7.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.783\n",
      "INFO:tensorflow:loss = 7.800106922830288e-08, step = 8301 (6.766 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.0394\n",
      "INFO:tensorflow:loss = 1.4183708538839342e-07, step = 8401 (6.647 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.687\n",
      "INFO:tensorflow:loss = 2.8714225520966696e-06, step = 8501 (7.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.268\n",
      "INFO:tensorflow:loss = 1.226175692025541e-06, step = 8601 (8.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.0825\n",
      "INFO:tensorflow:loss = 1.968558217737531e-06, step = 8701 (7.644 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.526\n",
      "INFO:tensorflow:loss = 3.3268280035571453e-06, step = 8801 (7.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.2427\n",
      "INFO:tensorflow:loss = 9.186082952827553e-07, step = 8901 (7.022 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.5677\n",
      "INFO:tensorflow:loss = 8.12285520234257e-06, step = 9001 (7.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.0955\n",
      "INFO:tensorflow:loss = 2.6516966850757126e-07, step = 9101 (7.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.5084\n",
      "INFO:tensorflow:loss = 3.7964559359266905e-07, step = 9201 (7.998 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.3902\n",
      "INFO:tensorflow:loss = 3.627282605116104e-06, step = 9301 (8.069 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.0329\n",
      "INFO:tensorflow:loss = 3.4180678772077316e-07, step = 9401 (8.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9845\n",
      "INFO:tensorflow:loss = 1.5654952160036608e-06, step = 9501 (7.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.3683\n",
      "INFO:tensorflow:loss = 9.763747876447367e-07, step = 9601 (6.960 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.7295\n",
      "INFO:tensorflow:loss = 3.2078967270141594e-07, step = 9701 (7.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.0235\n",
      "INFO:tensorflow:loss = 4.7007378218111717e-07, step = 9801 (8.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.8468\n",
      "INFO:tensorflow:loss = 1.11001027754765e-05, step = 9901 (8.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5621\n",
      "INFO:tensorflow:loss = 5.2798697979324516e-05, step = 10001 (8.653 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.1473\n",
      "INFO:tensorflow:loss = 2.366509103389504e-05, step = 10101 (8.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.4132\n",
      "INFO:tensorflow:loss = 3.902859270010725e-05, step = 10201 (7.455 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.8286\n",
      "INFO:tensorflow:loss = 0.00010201913908764235, step = 10301 (7.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9717\n",
      "INFO:tensorflow:loss = 5.692570009470299e-07, step = 10401 (7.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.334\n",
      "INFO:tensorflow:loss = 1.676843632949312e-05, step = 10501 (7.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9122\n",
      "INFO:tensorflow:loss = 1.8609743187752482e-06, step = 10601 (7.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.5486\n",
      "INFO:tensorflow:loss = 1.6359113758011773e-05, step = 10701 (7.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.5997\n",
      "INFO:tensorflow:loss = 4.798100905305864e-05, step = 10801 (7.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.521\n",
      "INFO:tensorflow:loss = 3.6950288286523396e-06, step = 10901 (7.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.1407\n",
      "INFO:tensorflow:loss = 9.785739983598316e-06, step = 11001 (7.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.2962\n",
      "INFO:tensorflow:loss = 6.457303767517172e-05, step = 11101 (8.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.0513\n",
      "INFO:tensorflow:loss = 3.511073674418398e-05, step = 11201 (7.662 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.3852\n",
      "INFO:tensorflow:loss = 1.0786474521189376e-05, step = 11301 (7.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9913\n",
      "INFO:tensorflow:loss = 5.097324695316439e-05, step = 11401 (7.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.4104\n",
      "INFO:tensorflow:loss = 0.0007833558495381677, step = 11501 (7.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.5046\n",
      "INFO:tensorflow:loss = 1.6651412128800576e-05, step = 11601 (7.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.2224\n",
      "INFO:tensorflow:loss = 1.4549934838944238e-06, step = 11701 (7.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.0986\n",
      "INFO:tensorflow:loss = 1.1913899847114745e-05, step = 11801 (7.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0184\n",
      "INFO:tensorflow:loss = 7.485493811120891e-05, step = 11901 (9.076 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.1957\n",
      "INFO:tensorflow:loss = 1.1403344990498113e-05, step = 12001 (7.045 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-d83da63cf691>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1133\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1134\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m   1136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1334\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    575\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1051\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1053\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1054\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1199\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1201\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "estimator.train(input_fn=input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: ('eins', 0),\n",
       " 5: ('fünf', 0),\n",
       " 21: ('einundzwanzig', 0),\n",
       " 41: ('einundvierzig', 0),\n",
       " 47: ('siebenundvierzig', 0),\n",
       " 56: ('sechsundfünfzig', 1),\n",
       " 66: ('sechsundsechzig', 1),\n",
       " 77: ('siebenundsiebzig', 0),\n",
       " 80: ('undachtzig', 1),\n",
       " 95: ('fünfundneunzig', 0)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1553: 'eintausendfünfhundretdreiundfünfzig',\n",
       " 32708: 'zweiunddreiβigtausendsiebenhundretacht',\n",
       " 33142: 'dreiunddreiβigtausendeinhundretzweiundvierzig',\n",
       " 33302: 'dreiunddreiβigtausenddreihundretzwei',\n",
       " 41489: 'einundvierzigtausendvierhundretneunundachtzig',\n",
       " 59702: 'neunundfünfzigtausendsiebenhundretzwei',\n",
       " 76251: 'sechsundsiebzigtausendzweihundreteinundfünfzig',\n",
       " 77279: 'siebenundsiebzigtausendzweihundretneunundsiebzig',\n",
       " 84168: 'vierundachtzigtausendeinhundretachtundsechzig',\n",
       " 90285: 'undneunzigtausendzweihundretfünfundachtzig'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "createNum2WordDict(size=10,high=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
